# SVM
man_grid <- expand.grid(cost = c(1:10))
ctrl <- trainControl(method="cv", number = 1)
svm <- train(class ~ ., data = train, method = "svmLinear2", trControl = ctrl, tuneGrid = man_grid)
# stopCluster(cl)
# Evaluate
lr_accuracy <- sum(predict(lr, test) == test$class) / nrow(test)
lda_accuracy <- sum(predict(lda_model, test)$class == test$class) / nrow(test)
knn_accuracy <- sum(predict(knn, test) == test$class) / nrow(test)
svm_accuracy <- sum(predict(svm, test) == test$class) / nrow(test)
# print(paste(lr_accuracy, ",", lda_accuracy, ",", knn_accuracy, ",", svm_accuracy))
}
now <- Sys.time()
for (i in c(1:10)) {
print(i)
main()
}
print(Sys.time() - now)
library(readr)
library(nnet)
library(MASS)
library(caret)
library(e1071)
library(doParallel)
main <- function() {
header <- c("sepal_length", "sepal_width", "petal_length", "petal_width", "class")
iris <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data")
names(iris) <- header
sample <- sample.int(n = nrow(iris), size = floor(.8 * nrow(iris)), replace=F)
train <- iris[sample, ]
test  <- iris[-sample, ]
cl <- makePSOCKcluster(3)
registerDoParallel(cl)
# logistic regression
lr <- multinom(class ~ ., data = train)
# linear discriminant analysis
lda_model <- lda(class ~ ., data = train)
# KNN
man_grid <- expand.grid(k = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
knn <- train(class ~ ., data = train, method = "knn", trControl = ctrl, tuneGrid = man_grid)
# SVM
man_grid <- expand.grid(cost = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
svm <- train(class ~ ., data = train, method = "svmLinear2", trControl = ctrl, tuneGrid = man_grid)
stopCluster(cl)
# Evaluate
lr_accuracy <- sum(predict(lr, test) == test$class) / nrow(test)
lda_accuracy <- sum(predict(lda_model, test)$class == test$class) / nrow(test)
knn_accuracy <- sum(predict(knn, test) == test$class) / nrow(test)
svm_accuracy <- sum(predict(svm, test) == test$class) / nrow(test)
# print(paste(lr_accuracy, ",", lda_accuracy, ",", knn_accuracy, ",", svm_accuracy))
}
now <- Sys.time()
for (i in c(1:10)) {
print(i)
main()
}
print(Sys.time() - now)
library(readr)
library(nnet)
library(MASS)
library(caret)
library(e1071)
library(doParallel)
main <- function() {
header <- c("sepal_length", "sepal_width", "petal_length", "petal_width", "class")
iris <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data")
names(iris) <- header
sample <- sample.int(n = nrow(iris), size = floor(.8 * nrow(iris)), replace=F)
train <- iris[sample, ]
test  <- iris[-sample, ]
cl <- makePSOCKcluster(3)
registerDoParallel(cl)
# logistic regression
lr <- multinom(class ~ ., data = train)
# linear discriminant analysis
lda_model <- lda(class ~ ., data = train)
# KNN
man_grid <- expand.grid(k = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
knn <- train(class ~ ., data = train, method = "knn", trControl = ctrl, tuneGrid = man_grid)
# SVM
man_grid <- expand.grid(cost = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
svm <- train(class ~ ., data = train, method = "svmLinear2", trControl = ctrl, tuneGrid = man_grid)
stopCluster(cl)
# Evaluate
lr_accuracy <- sum(predict(lr, test) == test$class) / nrow(test)
lda_accuracy <- sum(predict(lda_model, test)$class == test$class) / nrow(test)
knn_accuracy <- sum(predict(knn, test) == test$class) / nrow(test)
svm_accuracy <- sum(predict(svm, test) == test$class) / nrow(test)
# print(paste(lr_accuracy, ",", lda_accuracy, ",", knn_accuracy, ",", svm_accuracy))
}
now <- Sys.time()
for (i in c(1:10)) {
print(i)
main()
}
print(Sys.time() - now)
library(readr)
library(nnet)
library(MASS)
library(caret)
library(e1071)
library(doParallel)
main <- function() {
header <- c("sepal_length", "sepal_width", "petal_length", "petal_width", "class")
iris <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data")
names(iris) <- header
sample <- sample.int(n = nrow(iris), size = floor(.8 * nrow(iris)), replace=F)
train <- iris[sample, ]
test  <- iris[-sample, ]
cl <- makePSOCKcluster(3)
registerDoParallel(cl)
# logistic regression
lr <- multinom(class ~ ., data = train)
# linear discriminant analysis
lda_model <- lda(class ~ ., data = train)
# KNN
man_grid <- expand.grid(k = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
knn <- train(class ~ ., data = train, method = "knn", trControl = ctrl, tuneGrid = man_grid)
print("test1")
# SVM
man_grid <- expand.grid(cost = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
svm <- train(class ~ ., data = train, method = "svmLinear2", trControl = ctrl, tuneGrid = man_grid)
print("test2")
stopCluster(cl)
# Evaluate
lr_accuracy <- sum(predict(lr, test) == test$class) / nrow(test)
lda_accuracy <- sum(predict(lda_model, test)$class == test$class) / nrow(test)
knn_accuracy <- sum(predict(knn, test) == test$class) / nrow(test)
svm_accuracy <- sum(predict(svm, test) == test$class) / nrow(test)
# print(paste(lr_accuracy, ",", lda_accuracy, ",", knn_accuracy, ",", svm_accuracy))
}
now <- Sys.time()
for (i in c(1:10)) {
print(i)
main()
}
print(Sys.time() - now)
library(readr)
library(nnet)
library(MASS)
library(caret)
library(e1071)
library(doParallel)
main <- function() {
header <- c("sepal_length", "sepal_width", "petal_length", "petal_width", "class")
iris <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data")
names(iris) <- header
sample <- sample.int(n = nrow(iris), size = floor(.8 * nrow(iris)), replace=F)
train <- iris[sample, ]
test  <- iris[-sample, ]
cl <- makePSOCKcluster(3)
registerDoParallel(cl)
print("test1")
# logistic regression
lr <- multinom(class ~ ., data = train)
# linear discriminant analysis
lda_model <- lda(class ~ ., data = train)
print("test2")
# KNN
man_grid <- expand.grid(k = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
knn <- train(class ~ ., data = train, method = "knn", trControl = ctrl, tuneGrid = man_grid)
# SVM
man_grid <- expand.grid(cost = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
svm <- train(class ~ ., data = train, method = "svmLinear2", trControl = ctrl, tuneGrid = man_grid)
stopCluster(cl)
# Evaluate
lr_accuracy <- sum(predict(lr, test) == test$class) / nrow(test)
lda_accuracy <- sum(predict(lda_model, test)$class == test$class) / nrow(test)
knn_accuracy <- sum(predict(knn, test) == test$class) / nrow(test)
svm_accuracy <- sum(predict(svm, test) == test$class) / nrow(test)
# print(paste(lr_accuracy, ",", lda_accuracy, ",", knn_accuracy, ",", svm_accuracy))
}
now <- Sys.time()
for (i in c(1:10)) {
print(i)
main()
}
print(Sys.time() - now)
library(readr)
library(nnet)
library(MASS)
library(caret)
library(e1071)
library(doParallel)
main <- function() {
header <- c("sepal_length", "sepal_width", "petal_length", "petal_width", "class")
iris <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data")
names(iris) <- header
sample <- sample.int(n = nrow(iris), size = floor(.8 * nrow(iris)), replace=F)
train <- iris[sample, ]
test  <- iris[-sample, ]
cl <- makePSOCKcluster(3)
registerDoParallel(cl)
print("test1")
# logistic regression
lr <- multinom(class ~ ., data = train)
print("test2")
# linear discriminant analysis
lda_model <- lda(class ~ ., data = train)
print("test3")
# KNN
man_grid <- expand.grid(k = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
knn <- train(class ~ ., data = train, method = "knn", trControl = ctrl, tuneGrid = man_grid)
# SVM
man_grid <- expand.grid(cost = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
svm <- train(class ~ ., data = train, method = "svmLinear2", trControl = ctrl, tuneGrid = man_grid)
stopCluster(cl)
# Evaluate
lr_accuracy <- sum(predict(lr, test) == test$class) / nrow(test)
lda_accuracy <- sum(predict(lda_model, test)$class == test$class) / nrow(test)
knn_accuracy <- sum(predict(knn, test) == test$class) / nrow(test)
svm_accuracy <- sum(predict(svm, test) == test$class) / nrow(test)
# print(paste(lr_accuracy, ",", lda_accuracy, ",", knn_accuracy, ",", svm_accuracy))
}
now <- Sys.time()
for (i in c(1:10)) {
print(i)
main()
}
print(Sys.time() - now)
?multinom
library(readr)
library(nnet)
library(MASS)
library(caret)
library(e1071)
library(doParallel)
main <- function() {
header <- c("sepal_length", "sepal_width", "petal_length", "petal_width", "class")
iris <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data")
names(iris) <- header
sample <- sample.int(n = nrow(iris), size = floor(.8 * nrow(iris)), replace=F)
train <- iris[sample, ]
test  <- iris[-sample, ]
cl <- makePSOCKcluster(3)
registerDoParallel(cl)
print("test1")
# logistic regression
lr <- multinom(class ~ ., data = train, trace = F)
print("test2")
# linear discriminant analysis
lda_model <- lda(class ~ ., data = train)
print("test3")
# KNN
man_grid <- expand.grid(k = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
knn <- train(class ~ ., data = train, method = "knn", trControl = ctrl, tuneGrid = man_grid)
# SVM
man_grid <- expand.grid(cost = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
svm <- train(class ~ ., data = train, method = "svmLinear2", trControl = ctrl, tuneGrid = man_grid)
stopCluster(cl)
# Evaluate
lr_accuracy <- sum(predict(lr, test) == test$class) / nrow(test)
lda_accuracy <- sum(predict(lda_model, test)$class == test$class) / nrow(test)
knn_accuracy <- sum(predict(knn, test) == test$class) / nrow(test)
svm_accuracy <- sum(predict(svm, test) == test$class) / nrow(test)
# print(paste(lr_accuracy, ",", lda_accuracy, ",", knn_accuracy, ",", svm_accuracy))
}
now <- Sys.time()
for (i in c(1:10)) {
print(i)
main()
}
print(Sys.time() - now)
library(readr)
library(nnet)
library(MASS)
library(caret)
library(e1071)
library(doParallel)
main <- function() {
header <- c("sepal_length", "sepal_width", "petal_length", "petal_width", "class")
iris <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data")
names(iris) <- header
sample <- sample.int(n = nrow(iris), size = floor(.8 * nrow(iris)), replace=F)
train <- iris[sample, ]
test  <- iris[-sample, ]
cl <- makePSOCKcluster(3)
registerDoParallel(cl)
# logistic regression
lr <- multinom(class ~ ., data = train, trace = F)
# linear discriminant analysis
lda_model <- lda(class ~ ., data = train)
# KNN
man_grid <- expand.grid(k = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
knn <- train(class ~ ., data = train, method = "knn", trControl = ctrl, tuneGrid = man_grid)
# SVM
man_grid <- expand.grid(cost = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
svm <- train(class ~ ., data = train, method = "svmLinear2", trControl = ctrl, tuneGrid = man_grid)
stopCluster(cl)
# Evaluate
lr_accuracy <- sum(predict(lr, test) == test$class) / nrow(test)
lda_accuracy <- sum(predict(lda_model, test)$class == test$class) / nrow(test)
knn_accuracy <- sum(predict(knn, test) == test$class) / nrow(test)
svm_accuracy <- sum(predict(svm, test) == test$class) / nrow(test)
print(paste(lr_accuracy, ",", lda_accuracy, ",", knn_accuracy, ",", svm_accuracy))
}
now <- Sys.time()
for (i in c(1:10)) {
print(i)
main()
}
print(Sys.time() - now)
library(readr)
library(nnet)
library(MASS)
library(caret)
library(e1071)
library(doParallel)
main <- function() {
header <- c("sepal_length", "sepal_width", "petal_length", "petal_width", "class")
iris <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data")
names(iris) <- header
sample <- sample.int(n = nrow(iris), size = floor(.8 * nrow(iris)), replace=F)
train <- iris[sample, ]
test  <- iris[-sample, ]
cl <- makePSOCKcluster(1)
registerDoParallel(cl)
# logistic regression
lr <- multinom(class ~ ., data = train, trace = F)
# linear discriminant analysis
lda_model <- lda(class ~ ., data = train)
# KNN
man_grid <- expand.grid(k = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
knn <- train(class ~ ., data = train, method = "knn", trControl = ctrl, tuneGrid = man_grid)
# SVM
man_grid <- expand.grid(cost = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
svm <- train(class ~ ., data = train, method = "svmLinear2", trControl = ctrl, tuneGrid = man_grid)
stopCluster(cl)
# Evaluate
lr_accuracy <- sum(predict(lr, test) == test$class) / nrow(test)
lda_accuracy <- sum(predict(lda_model, test)$class == test$class) / nrow(test)
knn_accuracy <- sum(predict(knn, test) == test$class) / nrow(test)
svm_accuracy <- sum(predict(svm, test) == test$class) / nrow(test)
print(paste(lr_accuracy, ",", lda_accuracy, ",", knn_accuracy, ",", svm_accuracy))
}
now <- Sys.time()
for (i in c(1:10)) {
print(i)
main()
}
print(Sys.time() - now)
library(readr)
library(nnet)
library(MASS)
library(caret)
library(e1071)
library(doParallel)
main <- function() {
header <- c("sepal_length", "sepal_width", "petal_length", "petal_width", "class")
iris <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data")
names(iris) <- header
sample <- sample.int(n = nrow(iris), size = floor(.8 * nrow(iris)), replace=F)
train <- iris[sample, ]
test  <- iris[-sample, ]
# cl <- makePSOCKcluster(1)
# registerDoParallel(cl)
# logistic regression
lr <- multinom(class ~ ., data = train, trace = F)
# linear discriminant analysis
lda_model <- lda(class ~ ., data = train)
# KNN
man_grid <- expand.grid(k = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
knn <- train(class ~ ., data = train, method = "knn", trControl = ctrl, tuneGrid = man_grid)
# SVM
man_grid <- expand.grid(cost = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
svm <- train(class ~ ., data = train, method = "svmLinear2", trControl = ctrl, tuneGrid = man_grid)
# stopCluster(cl)
# Evaluate
lr_accuracy <- sum(predict(lr, test) == test$class) / nrow(test)
lda_accuracy <- sum(predict(lda_model, test)$class == test$class) / nrow(test)
knn_accuracy <- sum(predict(knn, test) == test$class) / nrow(test)
svm_accuracy <- sum(predict(svm, test) == test$class) / nrow(test)
print(paste(lr_accuracy, ",", lda_accuracy, ",", knn_accuracy, ",", svm_accuracy))
}
now <- Sys.time()
for (i in c(1:10)) {
print(i)
main()
}
print(Sys.time() - now)
library(readr)
library(nnet)
library(MASS)
library(caret)
library(e1071)
library(doParallel)
main <- function() {
header <- c("sepal_length", "sepal_width", "petal_length", "petal_width", "class")
iris <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data")
names(iris) <- header
sample <- sample.int(n = nrow(iris), size = floor(.8 * nrow(iris)), replace=F)
train <- iris[sample, ]
test  <- iris[-sample, ]
# logistic regression
lr <- multinom(class ~ ., data = train, trace = F)
# linear discriminant analysis
lda_model <- lda(class ~ ., data = train)
# KNN
man_grid <- expand.grid(k = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
knn <- train(class ~ ., data = train, method = "knn", trControl = ctrl, tuneGrid = man_grid)
# SVM
man_grid <- expand.grid(cost = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
svm <- train(class ~ ., data = train, method = "svmLinear2", trControl = ctrl, tuneGrid = man_grid)
# Evaluate
lr_accuracy <- sum(predict(lr, test) == test$class) / nrow(test)
lda_accuracy <- sum(predict(lda_model, test)$class == test$class) / nrow(test)
knn_accuracy <- sum(predict(knn, test) == test$class) / nrow(test)
svm_accuracy <- sum(predict(svm, test) == test$class) / nrow(test)
print(paste(lr_accuracy, ",", lda_accuracy, ",", knn_accuracy, ",", svm_accuracy))
}
now <- Sys.time()
for (i in c(1:10)) {
print(i)
main()
}
print(Sys.time() - now)
library(readr)
library(nnet)
library(MASS)
library(caret)
library(e1071)
library(doParallel)
main <- function() {
header <- c("sepal_length", "sepal_width", "petal_length", "petal_width", "class")
iris <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data")
names(iris) <- header
sample <- sample.int(n = nrow(iris), size = floor(.8 * nrow(iris)), replace=F)
train <- iris[sample, ]
test  <- iris[-sample, ]
# logistic regression
lr <- multinom(class ~ ., data = train, trace = F)
# linear discriminant analysis
lda_model <- lda(class ~ ., data = train)
# KNN
man_grid <- expand.grid(k = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
knn <- train(class ~ ., data = train, method = "knn", trControl = ctrl, tuneGrid = man_grid)
# SVM
man_grid <- expand.grid(cost = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
svm <- train(class ~ ., data = train, method = "svmLinear2", trControl = ctrl, tuneGrid = man_grid)
# Evaluate
lr_accuracy <- sum(predict(lr, test) == test$class) / nrow(test)
lda_accuracy <- sum(predict(lda_model, test)$class == test$class) / nrow(test)
knn_accuracy <- sum(predict(knn, test) == test$class) / nrow(test)
svm_accuracy <- sum(predict(svm, test) == test$class) / nrow(test)
# print(paste(lr_accuracy, ",", lda_accuracy, ",", knn_accuracy, ",", svm_accuracy))
}
now <- Sys.time()
for (i in c(1:10)) {
# print(i)
main()
}
print(Sys.time() - now)
1:25
library(readr)
library(nnet)
library(MASS)
library(caret)
library(e1071)
library(doParallel)
main <- function() {
header <- c("sepal_length", "sepal_width", "petal_length", "petal_width", "class")
iris <- read.csv("https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data")
names(iris) <- header
sample <- sample.int(n = nrow(iris), size = floor(.8 * nrow(iris)), replace=F)
train <- iris[sample, ]
test  <- iris[-sample, ]
# logistic regression
lr <- multinom(class ~ ., data = train, trace = F)
# linear discriminant analysis
lda_model <- lda(class ~ ., data = train)
# KNN
man_grid <- expand.grid(k = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
knn <- train(class ~ ., data = train, method = "knn", trControl = ctrl, tuneGrid = man_grid)
# SVM
man_grid <- expand.grid(cost = c(1:10))
ctrl <- trainControl(method="cv", number = 2)
svm <- train(class ~ ., data = train, method = "svmLinear2", trControl = ctrl, tuneGrid = man_grid)
# Evaluate
lr_accuracy <- sum(predict(lr, test) == test$class) / nrow(test)
lda_accuracy <- sum(predict(lda_model, test)$class == test$class) / nrow(test)
knn_accuracy <- sum(predict(knn, test) == test$class) / nrow(test)
svm_accuracy <- sum(predict(svm, test) == test$class) / nrow(test)
# print(paste(lr_accuracy, ",", lda_accuracy, ",", knn_accuracy, ",", svm_accuracy))
}
now <- Sys.time()
for (i in c(1:25)) {
main()
}
print(Sys.time() - now)
